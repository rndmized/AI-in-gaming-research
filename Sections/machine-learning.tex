\section{Machine Learning}
Even though Machine Learning has been a field of stud in computer science for the last 30 years, it was not until very recently that game developers started to implement it in their games. The lack of enthusiasm for adaptable behaviour in games typically responds to the fact that it is not really that important for a game to "learn". However, more and more developers release their games as services rather than products. Replayablity has become a huge factor, if using the same strategy over and over achieves always victory it gets tedious, more a chore than a challenge. A game that can learn adapt to its players has a higher chance to provide its users with more enjoyable situations.

\subsection{Defining Behaviour with AI}
Most games nowadays, either single or multi-player, have NPCs. Whether they are enemies, allies, unnamed or story characters it is important to define a behaviour pattern for therm to perform. However, players tend to reject erratic or inconsistent behaviour from agents, breaking game immersion. To create realistic behaviours that act in a more "human-like" manner is the aim of many AI researchers in the video game industry. In some cases, the goal of the agent is not to perform an action as perfect as a computer would, being the most efficient, but rather try to simulate imperfection. As well, in order for NPC to act as other players is necessary to emulate the lack of information a real player might have such as not being able to detect an enemy that is out of sight but act alert to the possibility of him coming. With that in mind Marvin T. Chan et al [12] designed an AI that emulated driving like a human would do through a race track providing a more challenging experience for the player. As stated in the paper "Although the playerâ€™s goal within the game is to win the race against the game-controlled car, the AI techniques adopted in the game are primarily designed to give the player an enjoyable time racing his or her car. In other words, the objective of winning by either side is not given the highest priority."
 


\vspace{2mm}
Defining the behaviour of the AI requires the expertise to be able to analyse and describe accurately such behaviour and script it accordingly. Chek Tien Tan and Ho-lun Cheng[11] proposed an agent personality representation model to provide an adaptable agent that can perform across a variety of games of different genres exhibiting a plausible adapted behaviour. The Tactical Agent Personality (TAP) is a framework model of progressive learning, to test its capabilities and evaluate the adaptability of the model three scenarios were created. In each scenario, TAP had a series of predefined behaviour with randomly assigned weights to start with and after every iteration a process starter to assimilate new weights (greedy search) and to assign a random value to seek new paths.

\vspace{2mm}
In the first scenario the model was tested against a First Person Shooter (FPS) environment. Three sets of experiments were performed. In the first set the AI was determined at random. In the second set the AI adapted its behaviour based on player performance. In the third set the AI adapted its behaviour base on the NPCs performance. The output of 500 tests per set demonstrated that the highest level of adaptability occurred when AI adaptation was based on the NPCs behaviour rather than player performance.

\vspace{2mm}
In the second scenario the model was tested against a Real-Time Strategy (RTS) environment. In addition to TAP, another layer of decision making was added, the Strategic Agent Personality (SAP). While TAP defined NPC behaviour at an individual level (short-term decisions), SAP determined their actions as a group (long-term decisions).

\vspace{2mm}
In the third scenario the model was tested against a Role-Playing Game (RPG) environment. In this test, the model was modified to switch the weight from the nodes or actions to the edges representing the temporary transitions between actions, Temporary Tactical Agent Personality (TTAP). The game consisted in two groups of characters 1 player and 5 NPCs. The first group implemented TAP while the second implemented TTAP. After running the experiment 500 times, the TTAP demonstrated a quicker adaptation but at the 500 the difference between the two models grow shorter and draws became more frequent.

\vspace{2mm}
TAP presents some interesting points such as high versatility and adaptation that reduces the need of specific scripting for actions escaping from more traditional approaches like Finite State Machines. TAP and SAP present a good performance and the scalability has low impact, however TTAP does not represent a better model over time and presents scalability issues as calculating the weight on the edges increments the overhead by a significant amount.


\subsection{Using Machine Learning to Increase Performance}
Subsection text here.
\vspace{2mm}